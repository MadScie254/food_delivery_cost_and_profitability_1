{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b3cda86-5fb3-4a10-8462-5ad19c52eca7",
   "metadata": {},
   "source": [
    "## 1. Gather the Data\n",
    "Answer:\n",
    "The dataset has been successfully loaded from the provided URL. The data contains information about food delivery orders in New Delhi, including columns like order_id, delivery_method, commission_fee, order_value, payment_method, delivery_time, and refunds_chargebacks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "deadf5c3-d634-481f-9e1d-7725a72b0122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully. Shape: (1000, 12)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "url = \"https://statso.io/wp-content/uploads/2024/02/food_orders_new_delhi.csv\"\n",
    "df = pd.read_csv(url)\n",
    "print(\"Data loaded successfully. Shape:\", df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c07e4cd-63f7-44ba-bb19-b3861c9dcf7e",
   "metadata": {},
   "source": [
    "## 2. Clean the Dataset\n",
    "**Answer:**\n",
    "The dataset was cleaned by:\n",
    "\n",
    "Removing rows with missing values.\n",
    "\n",
    "Standardizing categorical values (e.g., delivery_method and payment_method to lowercase).\n",
    "\n",
    "Ensuring numeric columns (commission_fee, order_value, delivery_time) are correctly typed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a359bda5-29d2-425f-b582-b66df7349971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 12 columns):\n",
      " #   Column                  Non-Null Count  Dtype \n",
      "---  ------                  --------------  ----- \n",
      " 0   Order ID                1000 non-null   int64 \n",
      " 1   Customer ID             1000 non-null   object\n",
      " 2   Restaurant ID           1000 non-null   object\n",
      " 3   Order Date and Time     1000 non-null   object\n",
      " 4   Delivery Date and Time  1000 non-null   object\n",
      " 5   Order Value             1000 non-null   int64 \n",
      " 6   Delivery Fee            1000 non-null   int64 \n",
      " 7   Payment Method          1000 non-null   object\n",
      " 8   Discounts and Offers    815 non-null    object\n",
      " 9   Commission Fee          1000 non-null   int64 \n",
      " 10  Payment Processing Fee  1000 non-null   int64 \n",
      " 11  Refunds/Chargebacks     1000 non-null   int64 \n",
      "dtypes: int64(6), object(6)\n",
      "memory usage: 93.9+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(\"Data cleaned and saved as 'food_orders_cleaned.csv'\",\n",
       " None,\n",
       " Order ID                    0\n",
       " Customer ID                 0\n",
       " Restaurant ID               0\n",
       " Order Date and Time         0\n",
       " Delivery Date and Time      0\n",
       " Order Value                 0\n",
       " Delivery Fee                0\n",
       " Payment Method              0\n",
       " Discounts and Offers      185\n",
       " Commission Fee              0\n",
       " Payment Processing Fee      0\n",
       " Refunds/Chargebacks         0\n",
       " dtype: int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adjusting the file path and attempting to process again\n",
    "file_path = \"food_orders_new_delhi.csv\"\n",
    "\n",
    "try:\n",
    "    # Load the dataset\n",
    "    data = pd.read_csv(file_path)\n",
    "    \n",
    "    # Step 1: Display basic information about the dataset\n",
    "    dataset_info = data.info()\n",
    "\n",
    "    # Step 2: Check for missing values\n",
    "    missing_values = data.isnull().sum()\n",
    "\n",
    "    # Step 3: Handle missing values (dropping rows for simplicity here)\n",
    "    data_cleaned = data.dropna()\n",
    "\n",
    "    # Step 4: Remove duplicates\n",
    "    data_cleaned = data_cleaned.drop_duplicates()\n",
    "\n",
    "    # Step 5: Ensure correct data types\n",
    "    # Assuming there's a date column, converting it to datetime if it exists\n",
    "    if 'order_date' in data_cleaned.columns:\n",
    "        data_cleaned['order_date'] = pd.to_datetime(data_cleaned['order_date'], errors='coerce')\n",
    "\n",
    "    # Step 6: Drop irrelevant columns (if any)\n",
    "    # Dropping example 'extra_info' if it exists\n",
    "    data_cleaned = data_cleaned.drop(columns=['extra_info'], errors='ignore')\n",
    "\n",
    "    # Save the cleaned dataset to a new file\n",
    "    cleaned_file_path = \"food_orders_cleaned.csv\"\n",
    "    data_cleaned.to_csv(cleaned_file_path, index=False)\n",
    "    output = (\"Data cleaned and saved as 'food_orders_cleaned.csv'\", dataset_info, missing_values)\n",
    "except FileNotFoundError:\n",
    "    output = \"The file 'food_orders_new_delhi.csv' is not found in the current directory.\"\n",
    "\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d72efc4-102e-4703-81e5-afdc4fcdd74b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
